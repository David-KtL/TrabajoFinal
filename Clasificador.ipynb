{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "998af4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras.layers import  Convolution2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88ffb2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d25a7c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_entrenamiento = 'C:/Project/data/train'\n",
    "data_validacion = 'C:/Project/data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a09488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parameters\n",
    "\"\"\"\n",
    "epocas=20\n",
    "longitud, altura = 150, 150\n",
    "batch_size = 32\n",
    "pasos = 50\n",
    "validation_steps = 300\n",
    "filtrosConv1 = 32\n",
    "filtrosConv2 = 64\n",
    "tamano_filtro1 = (3, 3)\n",
    "tamano_filtro2 = (2, 2)\n",
    "tamano_pool = (2, 2)\n",
    "clases = 7\n",
    "lr = 0.0004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8906b297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1633 images belonging to 7 classes.\n",
      "Found 809 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "##Preparamos nuestras imagenes\n",
    "entrenamiento_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "entrenamiento_generador = entrenamiento_datagen.flow_from_directory(\n",
    "    data_entrenamiento,\n",
    "    target_size=(altura, longitud),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validacion_generador = test_datagen.flow_from_directory(\n",
    "    data_validacion,\n",
    "    target_size=(altura, longitud),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ff5e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()\n",
    "cnn.add(Convolution2D(filtrosConv1, tamano_filtro1, padding =\"same\", input_shape=(longitud, altura, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f67daf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Convolution2D(filtrosConv2, tamano_filtro2, padding =\"same\"))\n",
    "cnn.add(MaxPooling2D(pool_size=tamano_pool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8357a942",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(256, activation='relu'))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(clases, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "012d3a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss='categorical_crossentropy',\n",
    "            optimizer=optimizers.Adam(learning_rate=lr),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "907deb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.7150 - accuracy: 0.5500WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 300 batches). You may need to use the repeat() function when building your dataset.\n",
      "50/50 [==============================] - 32s 641ms/step - loss: 1.7150 - accuracy: 0.5500 - val_loss: 0.9867 - val_accuracy: 0.6885\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 30s 595ms/step - loss: 0.9561 - accuracy: 0.6781\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 29s 579ms/step - loss: 0.7763 - accuracy: 0.7387\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 29s 578ms/step - loss: 0.6587 - accuracy: 0.7623\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 29s 583ms/step - loss: 0.5967 - accuracy: 0.7954\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 0.5027 - accuracy: 0.8235\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 29s 580ms/step - loss: 0.4569 - accuracy: 0.8311\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 29s 577ms/step - loss: 0.4042 - accuracy: 0.8604\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 30s 596ms/step - loss: 0.4299 - accuracy: 0.8451\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 29s 577ms/step - loss: 0.5092 - accuracy: 0.8203\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 29s 579ms/step - loss: 0.4375 - accuracy: 0.8426\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 29s 581ms/step - loss: 0.5671 - accuracy: 0.7954\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.4104 - accuracy: 0.8579\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 33s 655ms/step - loss: 0.3562 - accuracy: 0.8681\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 29s 577ms/step - loss: 0.3601 - accuracy: 0.8757\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 29s 569ms/step - loss: 0.3095 - accuracy: 0.8993\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 31s 613ms/step - loss: 0.2784 - accuracy: 0.9031\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 30s 603ms/step - loss: 0.3096 - accuracy: 0.8827\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 29s 586ms/step - loss: 0.5206 - accuracy: 0.8247\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 31s 617ms/step - loss: 0.2932 - accuracy: 0.8974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2682bedf5b0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(\n",
    "    entrenamiento_generador,\n",
    "    steps_per_epoch=pasos,\n",
    "    epochs=epocas,\n",
    "    validation_data=validacion_generador,\n",
    "    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f592cc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = './modelo/'\n",
    "if not os.path.exists(target_dir):\n",
    "  os.mkdir(target_dir)\n",
    "cnn.save('./modelo/modelo.h5')\n",
    "cnn.save_weights('./modelo/pesos.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688f769a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
